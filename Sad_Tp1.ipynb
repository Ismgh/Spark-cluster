{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mHnluIWyVPka"
   },
   "source": [
    "# Sad TP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ai2u4NO4Ygud"
   },
   "source": [
    "## Library's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "aiNUZWaRYeix"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import *\n",
    "from pyspark.sql import *\n",
    "from graphframes import *\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_bH6X0VXE5x"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessig part is done using only python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oXnrSsFOVBA9"
   },
   "outputs": [],
   "source": [
    "txt_file=\"data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pMry-HR4WxDa"
   },
   "outputs": [],
   "source": [
    "file = open(txt_file)\n",
    "clean_file=\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qpWoBrNZXPY2"
   },
   "outputs": [],
   "source": [
    "    for line in file:\n",
    "        #removing empty lines and spacial caracters\n",
    "        if line!=\"\\n\":\n",
    "            clean_file+=re.sub('[^A-Za-z0-9\\s]+', '',line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "aw66ADRPZDPH"
   },
   "outputs": [],
   "source": [
    "clean_file.replace(\"\\n\",\" \")\n",
    "f = open('preprocessed-data.txt', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pk0K_WP1aPiH",
    "outputId": "496225c5-15fc-4c93-e69b-13140a000d02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6246720"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.write(clean_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Project', 'Gutenberg', 'EBook', 'of']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words=spark.sparkContext.textFile(\"preprocessed-data.txt\").flatMap(lambda line: line.split(\" \"))\n",
    "words.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the table of paires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will give for each word an id then wee will join them by their keys (the key is incremented by 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'The'), (2, 'Project'), (4, 'Gutenberg'), (6, 'EBook'), (8, 'of')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=words.zipWithIndex().map(lambda x: ( x[1]*2,x[0]))\n",
    "y.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 'The'), (4, 'Project'), (6, 'Gutenberg'), (8, 'EBook'), (10, 'of')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=y.map(lambda x: (x[0]+2, x[1]))\n",
    "x.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'Project'), ('Project', 'Gutenberg'), ('Gutenberg', 'EBook')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy=x.join(y).map(lambda x: x[1])\n",
    "xy.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting the pairs frequency #(Xi,Yj) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('when', 'viewing'), 2), (('the', 'whole'), 451), (('for', 'the'), 1274)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psfq=xy.map(lambda x: (x,1)).reduceByKey(operator.add)\n",
    "psfq.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting the pairs frequency of words #(Yj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 7106), ('Project', 221), ('Gutenberg', 98)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsfq=words.map(lambda word: (word, 1)).reduceByKey(operator.add)\n",
    "wsfq.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting the pairs relative frequency of words #(Xi,Yj) / #(Yj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-To do this task we add the word Yj to the RDD who has the pairs frequency so we can join him with the RDD who contains the words frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('About', 'Project'), 0.00904977375565611),\n",
       " (('phrase', 'Project'), 0.03619909502262444),\n",
       " (('official', 'Project'), 0.00904977375565611)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psrfq=wsfq.join(psfq.map(lambda x:(x[0][1],x,x[1]))).map(lambda x:(x[1][1][0],x[1][1][1]/x[1][0]))\n",
    "psrfq.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. The 1000 most frequent pairs (Xi , Yj) sorted by:(Yj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of elements to show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|       _1|   _2|\n",
      "+---------+-----+\n",
      "|     [, ]|24066|\n",
      "|[of, the]|12439|\n",
      "|[in, the]| 5754|\n",
      "+---------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "psfq.sortBy(lambda x: (x[1],x[0][1]), False).toDF().show(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. The 1000 most frequent pairs (Xi , Yj) sorted by:#(Xi,Yj) / #(Yj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+\n",
      "|                  _1| _2|\n",
      "+--------------------+---+\n",
      "|    [the, zygomatic]|1.0|\n",
      "|   [process, zygoma]|1.0|\n",
      "|   [tender, zonenot]|1.0|\n",
      "|          [dat, zis]|1.0|\n",
      "|          [of, zinc]|1.0|\n",
      "|       [boss, zides]|1.0|\n",
      "|            [, zeus]|1.0|\n",
      "|     [my, zeropoint]|1.0|\n",
      "|        [and, zeres]|1.0|\n",
      "|       [the, zenith]|1.0|\n",
      "|          [and, zen]|1.0|\n",
      "|       [to, zakuska]|1.0|\n",
      "|    [with, youvodka]|1.0|\n",
      "|       [to, youturn]|1.0|\n",
      "|      [to, youthose]|1.0|\n",
      "|[his, youthfulnes...|1.0|\n",
      "|[shrewd, youthfully]|1.0|\n",
      "|      [told, youthe]|1.0|\n",
      "|[frightened, yousit]|1.0|\n",
      "|       [in, yourshe]|1.0|\n",
      "|[othersthe, young...|1.0|\n",
      "|[splendid, youngs...|1.0|\n",
      "|         [to, youis]|1.0|\n",
      "|      [beg, yougive]|1.0|\n",
      "|      [for, youeven]|1.0|\n",
      "|    [tell, youPeter]|1.0|\n",
      "|      [for, youJems]|1.0|\n",
      "|       [, yorkshire]|1.0|\n",
      "|            [, york]|1.0|\n",
      "|            [, yore]|1.0|\n",
      "|             [, yon]|1.0|\n",
      "|       [were, yoked]|1.0|\n",
      "|[quite, yieldedwent]|1.0|\n",
      "|       [beaux, yeux]|1.0|\n",
      "|       [and, yetyes]|1.0|\n",
      "|  [just, yetsomeday]|1.0|\n",
      "|        [as, yetbut]|1.0|\n",
      "|   [me, yesterdaywe]|1.0|\n",
      "|     [Kremlin, yesI]|1.0|\n",
      "|             [, yer]|1.0|\n",
      "|             [, yep]|1.0|\n",
      "|        [it, yelped]|1.0|\n",
      "|[small, yellowish...|1.0|\n",
      "| [a, yellowishgreen]|1.0|\n",
      "|      [a, yellowing]|1.0|\n",
      "|[largeboned, yell...|1.0|\n",
      "|   [a, yellowbacked]|1.0|\n",
      "|      [a, yearwhich]|1.0|\n",
      "|       [a, yearwhen]|1.0|\n",
      "|[fortyfive, years...|1.0|\n",
      "|[fourteen, yearsu...|1.0|\n",
      "|[for, yearsthoughts]|1.0|\n",
      "|   [ten, yearslater]|1.0|\n",
      "|      [some, yearsI]|1.0|\n",
      "| [ten, years186878a]|1.0|\n",
      "|        [, yearning]|1.0|\n",
      "|          [, yearly]|1.0|\n",
      "|        [a, yearand]|1.0|\n",
      "|             [, yea]|1.0|\n",
      "|         [he, yawns]|1.0|\n",
      "|            [, yarn]|1.0|\n",
      "|       [own, yardwe]|1.0|\n",
      "|          [, yankee]|1.0|\n",
      "|            [, yale]|1.0|\n",
      "|          [, yahweh]|1.0|\n",
      "|           [, yacht]|1.0|\n",
      "|  [Consequently, xy]|1.0|\n",
      "|       [in, xrange6]|1.0|\n",
      "| [the, xiphisternum]|1.0|\n",
      "|              [, xi]|1.0|\n",
      "|         [, wyoming]|1.0|\n",
      "|      [only, wuined]|1.0|\n",
      "|       [in, wryneck]|1.0|\n",
      "|    [of, wrongdoers]|1.0|\n",
      "|[NUMBER, wrnpc12txt]|1.0|\n",
      "|    [or, wrnpc11zip]|1.0|\n",
      "| [named, wrnpc11txt]|1.0|\n",
      "|[LETTER, wrnpc11a...|1.0|\n",
      "|[was, writtenthough]|1.0|\n",
      "|    [hut, writinghe]|1.0|\n",
      "|      [in, writinga]|1.0|\n",
      "|     [the, wristfor]|1.0|\n",
      "|          [, wright]|1.0|\n",
      "|    [that, wriggles]|1.0|\n",
      "|    [a, wretchthats]|1.0|\n",
      "|    [, wretchedness]|1.0|\n",
      "|      [in, wresting]|1.0|\n",
      "|      [by, wrecking]|1.0|\n",
      "|     [the, wreckers]|1.0|\n",
      "|       [a, wrathful]|1.0|\n",
      "|       [to, wrangle]|1.0|\n",
      "|       [dull, wrack]|1.0|\n",
      "|        [a, woundup]|1.0|\n",
      "|[whole, woundsurf...|1.0|\n",
      "|[accidental, woun...|1.0|\n",
      "|   [of, woundsModes]|1.0|\n",
      "|       [a, woundfor]|1.0|\n",
      "|   [of, woundedsome]|1.0|\n",
      "|[slightly, wounde...|1.0|\n",
      "|     [a, woundAcute]|1.0|\n",
      "+--------------------+---+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "psrfq.sortBy(lambda x: (x[1],x[0][1]), False).toDF().show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The 1000 most frequent pairs of each word (Yj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('tender', 'zonenot'), 1.0),\n",
       " (('', 'zeus'), 1.0),\n",
       " (('my', 'zeropoint'), 1.0),\n",
       " (('and', 'zeres'), 1.0),\n",
       " (('and', 'zen'), 1.0)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psrfq.sortBy(lambda x: (x[1],x[0][1]), False).distinct().take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be continued..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Sad-Tp.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
