{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mHnluIWyVPka"
   },
   "source": [
    "# Sad TP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ai2u4NO4Ygud"
   },
   "source": [
    "## Library's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "aiNUZWaRYeix"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import *\n",
    "from pyspark.sql import *\n",
    "from graphframes import *\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_bH6X0VXE5x"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessig part is done using only python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oXnrSsFOVBA9"
   },
   "outputs": [],
   "source": [
    "txt_file=\"data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pMry-HR4WxDa"
   },
   "outputs": [],
   "source": [
    "file = open(txt_file)\n",
    "clean_file=\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qpWoBrNZXPY2"
   },
   "outputs": [],
   "source": [
    "    for line in file:\n",
    "        #removing empty lines and spacial caracters\n",
    "        if line!=\"\\n\":\n",
    "            clean_file+=re.sub('[^A-Za-z0-9\\s]+', '',line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "aw66ADRPZDPH"
   },
   "outputs": [],
   "source": [
    "clean_file.replace(\"\\n\",\" \")\n",
    "f = open('preprocessed-data.txt', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pk0K_WP1aPiH",
    "outputId": "496225c5-15fc-4c93-e69b-13140a000d02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6246720"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.write(clean_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Project', 'Gutenberg', 'EBook', 'of']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words=spark.sparkContext.textFile(\"preprocessed-data.txt\").flatMap(lambda line: line.split(\" \"))\n",
    "words.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the table of paires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will give for each word an id then wee will join them by their keys (the key is incremented by 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'The'), (2, 'Project'), (4, 'Gutenberg'), (6, 'EBook'), (8, 'of')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=words.zipWithIndex().map(lambda x: ( x[1]*2,x[0]))\n",
    "y.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 'The'), (4, 'Project'), (6, 'Gutenberg'), (8, 'EBook'), (10, 'of')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=y.map(lambda x: (x[0]+2, x[1]))\n",
    "x.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'Project'), ('Project', 'Gutenberg'), ('Gutenberg', 'EBook')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy=x.join(y).map(lambda x: x[1])\n",
    "xy.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting the pairs frequency #(Xi,Yj) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('when', 'viewing'), 2), (('the', 'whole'), 451), (('for', 'the'), 1274)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psfq=xy.map(lambda x: (x,1)).reduceByKey(operator.add)\n",
    "psfq.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting the pairs frequency of words #(Yj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 7106), ('Project', 221), ('Gutenberg', 98)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsfq=words.map(lambda word: (word, 1)).reduceByKey(operator.add)\n",
    "wsfq.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting the pairs relative frequency of words #(Xi,Yj) / #(Yj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-To do this task we add the word Yj to the RDD who has the pairs frequency so we can join him with the RDD who contains the words frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('About', 'Project'), 0.00904977375565611),\n",
       " (('phrase', 'Project'), 0.03619909502262444),\n",
       " (('official', 'Project'), 0.00904977375565611)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psrfq=wsfq.join(psfq.map(lambda x:(x[0][1],x,x[1]))).map(lambda x:(x[1][1][0],x[1][1][1]/x[1][0]))\n",
    "psrfq.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. The 1000 most frequent pairs (Xi , Yj) sorted by:(Yj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of elements to show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|       _1|   _2|\n",
      "+---------+-----+\n",
      "|     [, ]|24066|\n",
      "|[of, the]|12439|\n",
      "|[in, the]| 5754|\n",
      "+---------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "psfq.sortBy(lambda x: (x[1],x[0][1]), False).toDF().show(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. The 1000 most frequent pairs (Xi , Yj) sorted by:#(Xi,Yj) / #(Yj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psrfq.sortBy(lambda x: (x[1],x[0][1]), False).toDF().show(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The 1000 most frequent pairs of each word (Yj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('tender', 'zonenot'), 1.0),\n",
       " (('', 'zeus'), 1.0),\n",
       " (('my', 'zeropoint'), 1.0),\n",
       " (('and', 'zeres'), 1.0),\n",
       " (('and', 'zen'), 1.0)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psrfq.sortBy(lambda x: (x[1],x[0][1]), False).distinct().take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be continued..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Sad-Tp.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
